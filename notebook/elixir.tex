\documentclass[10pt, a4paper]{article}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{listings}

\colorlet{shadecolor}{blue!20}

\newcommand{\includecode}[3]{\lstinputlisting[caption=#1, label=#2]{#3}}

\begin{document}
\title{Command Line Application with Elixir}
\author{Pierre Sugar\\
\texttt{pierre@sugaryourcoffee.de}}
\date{\today}
\maketitle

\begin{abstract}
The programming world gets parallel because of processors with multiple cores.
Most of the programming languages aren't build for multiprocessing and hence
cannot use the performance that comes with the multi core processors. Erlang is
one of the most sophisticated language build especially for multiprocessing.
But Erlang has some get to used rules and is not so much fun to program with.
This is where Elixir comes into play. Elixir combines the advantages of Erlang
with the elegance of Ruby.

This tutorial is introducing into Elixir by developing a command line interface
based on a suggestion from Dave Thomas' Elixir book. 
\end{abstract}

\section{Installation}
\texttt{Elixir} is run on the \texttt{Erlang} virtual machine. That is we need
\texttt{Elixir} and \texttt{Erlang} installed. The most up to date installation
instructions for \texttt{Elixir} can be found at 
\url{http://elixir-lang.org/install.html} and for \texttt{Erlang} at
\url{https://www.erlang-solutions.com/downloads/download-erlang-otp}.

To install \texttt{Erlang} we issue following commands from the command line

\begin{verbatim}
\$ wget http://package.erlang-solutions.com/erlang-solutions_1.0_all.deb
\$ sudo dpkg -i erlang-solutions_1.0_all.deb
\$ wget http://package.erlang-solutions.com/ubuntu/erlang_solutions.asc
\$ sudo apt-key add erlang_solutions erlang_solutions.asc
\$ sudo apt-get update
\$ sudo apt-get install erlang
\end{verbatim}

Next we install \texttt{Elixir}

\begin{verbatim}
\$ wget http://packages.erlang-solutions._1.0_all.deb 
\$ sudo dpkg -i erlang-solutions_1.0_all.deb
\$ sudo apt-get update
\$ sudo apt-get install elixir
\end{verbatim}

Now we are ready to go.

\section{Define the Project}
The \texttt{National Climatic Data Center} or short \texttt{NOAA} is providing
web services to retrieve climatic data from cities of the American continent.
We want to retrieve this data with our application and display it on the
console.

\subsection{Project outline}
The program runs from the command line. We will provide a location and the
program will print the wheather data.

\begin{itemize}
  \item Provide location \$ noaa <location>
  \item Parse the input
  \item Fetch the data from NOAA
  \item Extract the wheather data
  \item Print the results
\end{itemize}

But before we jump into the application development we need to understand the
web service from \texttt{NOAA} to know what we actually have to provide as
parameters.

\subsection{Understanding the NOAA Web Service}
To use the web service from \texttt{NOAA} we need to request a token. With each
web service request we have to provide that token.

To request a token go to \url{https://www.ncdc.noaa.gov/cdo-web/token} and 
enter and submit your e-mail address. You will receive a token send to the 
provided e-mail address. This token you allways have to provide when sending
a web service request to \texttt{NOAA}.

Let's check out the web service with \texttt{curl}. Information about how to use
the web service can be found at 
\url{https://www.ncdc.noaa.gov/cdo-web/webservices/v2}. The \texttt{-H} switch
includes an extra header with the token to the HTTP \texttt{get} request.

To know wich locations are available to retrieve wheather data for we can
retrieve the data with the \texttt{/locations} url.

\begin{verbatim}
\$ curl -H "token:pLCcTVobSdphuEvXyOyhkAbVlObmWQra" \
        http://www.ncdc.noaa.gov/cdo-web/api/v2/locations
{"results":[
 {"id":"CITY:AE000002",
  "name":"Ajman, AE",
  "datacoverage":0.6855,
  "mindate":"1944-03-01",
  "maxdate":"2014-12-29"},
 {"id":"CITY:AE000003",
  "name":"Dubai, AE",
  "datacoverage":0.6855,
  "mindate":"1944-03-01",
  "maxdate":"2014-12-29"},
  ...
 {"id":"CITY:AR000010",
  "name":"Mendoza, AR",
  "datacoverage":0.997,
  "mindate":"1959-10-01",
  "maxdate":"2014-12-29"},
 {"id":"CITY:AR000011",
  "name":"Neuquen, AR",
  "datacoverage":0.9814,
  "mindate":"1956-08-01",
  "maxdate":"2014-12-29"}],
 "metadata":{"resultset":{"limit":25,"count":38497,"offset":1}}}
\end{verbatim}

As we can see the data is provided in a JSON format with \texttt{"results"} and
\texttt{"metadata"} fields. But it seems there are loads of locations. That is
our application also has to provided a way to list all available location data.

The data is provided in different datasets. Dependent the information we want
to retrieve we have to know the datasets \texttt{datatypeid}. We can obtain the
information with the \texttt{/datasets} url.

\begin{verbatim}
\$ curl -H "token:pLCcTVobSdphuEvXyOyhkAbVlObmWQra" \
        http://www.ncdc.noaa.gov/cdo-web/api/v2/datasets
{"results":[
  {"uid":"gov.noaa.ncdc:C00040","id":"ANNUAL","name":"Annual Summaries",
   "datacoverage":1,"mindate":"1831-02-01","maxdate":"2014-07-01"},
  {"uid":"gov.noaa.ncdc:C00861","id":"GHCND","name":"Daily Summaries",
   "datacoverage":1,"mindate":"1763-01-01","maxdate":"2014-12-31"},
  {"uid":"gov.noaa.ncdc:C00841","id":"GHCNDMS","name":"Monthly Summaries",
   "datacoverage":1,"mindate":"1763-01-01","maxdate":"2014-11-01"},
  {"uid":"gov.noaa.ncdc:C00345","id":"NEXRAD2",
   "name":"Weather Radar (Level II)",
   "datacoverage":0.95,"mindate":"1991-06-05","maxdate":"2014-12-31"},
  {"uid":"gov.noaa.ncdc:C00708","id":"NEXRAD3",
   "name":"Weather Radar (Level III)",
   "datacoverage":0.95,"mindate":"1994-05-20","maxdate":"2014-12-28"},
  {"uid":"gov.noaa.ncdc:C00821","id":"NORMAL_ANN",
   "name":"Normals Annual/Seasonal",
   "datacoverage":1,"mindate":"2010-01-01","maxdate":"2010-01-01"},
  {"uid":"gov.noaa.ncdc:C00823","id":"NORMAL_DLY","name":"Normals Daily",
   "datacoverage":1,"mindate":"2010-01-01","maxdate":"2010-12-31"},
  {"uid":"gov.noaa.ncdc:C00824","id":"NORMAL_HLY","name":"Normals Hourly",
   "datacoverage":1,"mindate":"2010-01-01","maxdate":"2010-12-31"},
  {"uid":"gov.noaa.ncdc:C00822","id":"NORMAL_MLY","name":"Normals Monthly",
   "datacoverage":1,"mindate":"2010-01-01","maxdate":"2010-12-01"},
  {"uid":"gov.noaa.ncdc:C00505","id":"PRECIP_15",
   "name":"Precipitation 15 Minute",
   "datacoverage":0.25,"mindate":"1970-05-12","maxdate":"2013-07-01"},
  {"uid":"gov.noaa.ncdc:C00313","id":"PRECIP_HLY",
   "name":"Precipitation Hourly",
   "datacoverage":1,"mindate":"1900-01-01","maxdate":"2013-10-01"}],
 "metadata":{"resultset":{"limit":25,"count":11,"offset":1}}}
\end{verbatim}

This information we have to additionally provide to the location information
for that we want to retrieve data from. Hence we also have to provide a way to
retrieve possible datasets with our application. 

From the \texttt{location} information we can obtain the min and max date 
weather data is available for each country. From the \texttt{dataset} 
information we can obtain which datasets are available. Based on that 
information we call the \texttt{data} url to retrieve the weather data.

And finally to retrieve actual weather data we invoke the \texttt{/data} url
with the \texttt{datasetid} GHCND and the \texttt{locationid} CITY:000019 for
Munich.

\begin{verbatim}
\$ curl -H "token:pLCcTVobSdphuEvXyOyhkAbVlObmWQra" \
        http://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&\
        locationid=CITY:GM000019&startdate=2014-10-01&enddate=2014-10-31
{"results":[
  {"station":"GHCND:GM000004199","value":14,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GM000004199","value":0,"attributes":",,E,",
  "datatype":"SNWD","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GM000004199","value":193,"attributes":",,E,",
  "datatype":"TMAX","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GM000004199","value":120,"attributes":",,E,",
  "datatype":"TMIN","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GME00111524","value":3,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GME00111524","value":0,"attributes":",,E,",
  "datatype":"SNWD","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GME00111524","value":191,"attributes":",,E,",
  "datatype":"TMAX","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GME00111524","value":104,"attributes":",,E,",
  "datatype":"TMIN","date":"2014-10-01T00:00:00"},
  {"station":"GHCND:GM000004199","value":0,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GM000004199","value":0,"attributes":",,E,",
  "datatype":"SNWD","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GM000004199","value":195,"attributes":",,E,",
  "datatype":"TMAX","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GM000004199","value":105,"attributes":",,E,",
  "datatype":"TMIN","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GME00111524","value":0,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GME00111524","value":0,"attributes":",,E,",
  "datatype":"SNWD","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GME00111524","value":184,"attributes":",,E,",
  "datatype":"TMAX","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GME00111524","value":73,"attributes":",,E,",
  "datatype":"TMIN","date":"2014-10-02T00:00:00"},
  {"station":"GHCND:GM000004199","value":0,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GM000004199","value":0,"attributes":",,E,",
  "datatype":"SNWD","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GM000004199","value":182,"attributes":",,E,",
  "datatype":"TMAX","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GM000004199","value":89,"attributes":",,E,",
  "datatype":"TMIN","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GME00111524","value":0,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GME00111524","value":0,"attributes":",,E,",
  "datatype":"SNWD","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GME00111524","value":184,"attributes":",,E,",
  "datatype":"TMAX","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GME00111524","value":67,"attributes":",,E,",
  "datatype":"TMIN","date":"2014-10-03T00:00:00"},
  {"station":"GHCND:GM000004199","value":0,"attributes":",,E,",
  "datatype":"PRCP","date":"2014-10-04T00:00:00"}],
 "metadata":{"resultset":{"limit":25,"count":248,"offset":1}}}
\end{verbatim}

Now we have all information we need to build our command line interface which
will, from the current information state, provide these functions.

\begin{itemize}
  \item List a specified count of available \texttt{datasets}
  \item List all or selected count of available \texttt{locations}
  \item Search for a specific city and print the \texttt{locationid}
  \item Get the wheather data for a specific location base on the 
    \texttt{locationid}
\end{itemize}

The invocation variants are listed in the table \ref{tbl:cli} on page 
\pageref{tbl:cli}.

\begin{table}[h]\footnotesize
  \caption{Command line interface}
  \begin{tabular}{p{5cm} p{7cm}}
    \hline
    \textbf{Command} & \textbf{Description} \\
    \hline
    noaa datasets -c 10 & Lists 10 datasets \\
    noaa datasets & Lists all available datasets \\
    noaa locations -c 10 & Lists 10 locations \\
    noaa locations & List all available locations \\
    noaa locations -s Munich & Searches of the Vancouver 
    \texttt{locationid} \\
    noaa data -l CITY:GM000019 -d GHCND -f 2014-10-01 -t 2014-10-31 &
    Print weather data for Munich (-l) for the specified dataset (-d)
    between 1st (-f) and 31st (-t) of October \\
    \hline
    \label{tbl:cli}
  \end{tabular}
\end{table}

\section{Create the Project}
\texttt{Elixir} comes with the tool \texttt{Mix} to create and manage 
\texttt{Elixir} projects.

To create a project we issue the \texttt{Mix} command \texttt{new}. But first
we change directory where we want to have created our project tree.

\begin{verbatim}
\$ cd ~/Learn/Elixir/noaa
\$ mix new noaa
* creating README.md
* creating .gitignore
* creating mix.exs
* creating config
* creating config/config.exs
* creating lib
* creating lib/noaa.ex
* creating test
* creating test/test_helper.exs
* creating test/noaa_test.exs

Your mix project was created successfully.
You can use mix to compile it, test it, and more:

  cd noaa
  mix test

Run 'mix help' for more commands.

\$
\end{verbatim}

Now we have a fully implemented project tree and we can right away run our 
first test.

\begin{verbatim}
\$ cd noaa
\$ mix test
Compiled lib/noaa.ex
Generated noaa.app
.

Finished in 0.07 seconds (0.07s on load, 0.00s on tests)
1 tests, 0 failures

Randomized with seed 963329
\$
\end{verbatim}

But before we actually start we want to set up version control for 
\texttt{noaa}.

\begin{verbatim}
\$ git init
\$ git add .
\$ git commit -am "Initial commit of noaa"
\end{verbatim}

\section{Implement the Command Line Interface}
Let's try behaviour driven development (BDD) with \texttt{Elixir}. 
\texttt{Elixir} comes with a test environment called \texttt{EXUnit}. With BDD
we start with tests first and then implement the code. So let's try that.

\includecode{test/cli\_test.exs}{lst:cli-test}{listings/cli_test.exs}

This is a bare test file with only a description we want to test. Let's run it
with

\begin{verbatim}
\$ mix test
** (CompileError) test/cli_test.exs:4: module Noaa.CLI is not loaded and could
not be found
    (stdlib) lists.erl:1352: :lists.mapfoldl/3
    (stdlib) lists.erl:1353: :lists.mapfoldl/3
\end{verbatim}

No surprise so far as we don't have an implementation of \texttt{Noaa.CLI} yet.
So the next step is to get it compiled. To do this we have to implement
\texttt{Noaa.CLI} next. As per convention the main source code of an 
application is saved into \texttt{lib/project\_name}. Our proeject's name is
\texttt{noaa}, hence our source code directory is named \texttt{lib/noaa}. Also
a each module is saved to a separate file and each module is name spaced with
the project name. So our first module for the command line interface (CLI) is
called \texttt{noaa.CLI}. Table \ref{tbl:conventions} on page 
\pageref{tbl:conventions} shows a summary of the conventions of \texttt{Elixir}
projects.

\begin{table}[h]\footnotesize
  \caption{Conventions for Elixir Projects}
  \begin{tabular}{p{2cm} p{10cm}}
    \hline
    \textbf{Command} & \textbf{Description} \\
    \hline
    \texttt{lib/noaa/} & Directory for main source code \\
    \texttt{noaa.CLI} & Each module is name spaced with the project name \\
                      & Each module lives in an own file \\

    \hline
    \label{tbl:conventions}
  \end{tabular}
\end{table}

\includecode{lib/noaa/cli.ex}{lst:cli}{listings/cli.ex}

With \texttt{cli.ex} in place we run the test again.

\begin{verbatim}
\$ mix test
Compiled lib/noaa/cli.ex
Generated noaa.app
test/cli_test.exs:4: warning: unused import Noaa.CLI
...........

Finished in 0.1 seconds (0.1s on load, 0.00s on tests)
11 tests, 0 failures

Randomized with seed 289389
\end{verbatim}

This looks good our tests ran successfully without errors - but actually this
is still boring. But now we get into the excitement. We now add our first 
actual test for \texttt{:help}.

\includecode{test/cli\_test1.exs}{lst:clitest1}{listings/cli_test1.exs}

Note that we didn't implement the function in \texttt{lib/noaa/cli.ex}. This
is why our test at that moment fails when we run \texttt{mix test}.

\includecode{mix test}{lst:testresult1}{listings/test-result1}

To make the test pass we will implement the parser section for \texttt{:help}.

\includecode{lib/noaa/cli2.ex}{lst:cli2}{listings/cli2.ex}

When we run the test again we will see all tests pass.

\includecode{mix test}{lst:testresult2}{listings/test-result2}

Now we implement the rest of the tests.

\includecode{test/cli2\_test}{lst:clitest}{listings/cli_test2.exs}

When we run the tests they should all fail except the one for \texttt{:help}.

\includecode{mix test}{lst:testresult3}{listings/test-result3}

To make them pass we implement the rest of the command line interface in 
\texttt{lib/cli.ex}

\includecode{lib/cli3.ex}{lst:cli3}{listings/cli3.ex}

And we see them all pass. There is a specialty regarding the \texttt{data}
command. This has more than one switch. Currently the switches have to be 
provided in a specific order. This is not user friendly. We should only make 
sure that all switches are provided. We write a test where we provide the 
switches in an arbitrary sequence.

\includecode{test/cli\_test3.exs}{lst:clitest3}{listings/cli_test3.exs}

If we run the test we see it fail.

\includecode{mix test}{lst:testresult5}{listings/test-result4}

To make it pass we have to refactor our code where we do the parsing. We
replace the \texttt{\_} and the \texttt{:data} parts with a function
\texttt{parse\_remains} that is trying to match the command line arguments 
that haven't been matched by the case statements before. 

\includecode{lib/cli4.ex}{lst:cli4}{listings/cli4.ex}

If we run the test again we see it pass.

\includecode{mix test}{lst:testresult6}{listings/test-result5}

Next we fetch the data from \texttt{NOAA}.

\section{Process the Parsed Command Line Data}
The next step is to process the parsed command line data. So we add a 
\texttt{process} function to our \texttt{run} function in the 
\texttt{Noaa.CLI} module. But before we do that we write the test.

\includecode{test/cli\_process\_test.exs}{lst:clitest4}
            {listings/cli_process_test.exs}

When we run the test we see it fail. To make the test pass we implement the
\texttt{process} function with that much functionality in the \texttt{Noaa.CLI}
module to make it pass. It is not the final solution but it makes the test pass 
and it shows that the process functions are invoked.

\includecode{lib/noaa/cli5.ex}{lst:cli5}{listings/cli5.ex}

When we run the test again we see it pass. We cannot test the 
\texttt{process(:help)} function because it calls \texttt{System.halt(0)} and
this will cancel the \texttt{mix test}. So we test if \texttt{:help} is
processed by running our function.

\includecode{Running the function with mix}{lst:mixhelp}{listings/run-help}

We see the nicely formatted \texttt{:help} message displayed. We can also run
the other commands. Let's do that.

\includecode{Running :data with mix}{lst:mixdata}{listings/run-data}

Of course we don't see any output yet but at least we see not error message. 
Now let's move on to implement the functionality to fetch the weather data
from \texttt{NOAA}.

\texttt{NOAA} is delivering data over a web service in the \texttt{JSON} 
format. To fetch and parse the data we will use external libraries from 
\url{http://hex.pm} which is similar to \url{https://rubygems.org} from where 
you can install external libraries to your proect.

\subsection{Installing external Libraries}
We will use (on advise of Dave Thomas) \texttt{HTTPoison} as the HTTP client
library and \texttt{jsx} as the \texttt{JSON} library.

To install the libraries we have to add them to \texttt{mix.exs} in the 
\texttt{deps} section.

\includecode{mix.exs}{lst:mixexs}{listings/mix.exs}

\texttt{\$ mix} is managing the dependencies for us. We can issue 
\texttt{\$ mix deps} to list the dependencies and their status. To download the
dependencies issue \texttt{\$ mix deps.get}. To actually install the
libraries issue \texttt{\$ mix deps} again.

Actual package management is done by \texttt{Hex}. If it is not installed 
yet you will be asked whether to install \texttt{Hex} when issuing 
\texttt{\$ mix deps}. With \texttt{\$ mix local} you can list available 
\texttt{Hex} tasks.

Now do the installation. First we list the dependencies and their status and on
the way install \texttt{Hex} if it not installed yet.

\texttt{\$ mix deps}

\includecode{mix deps}{lst:mixdeps}{listings/mix-deps}

Then downlaod the dependencies

\texttt{\$ mix deps.get}

\includecode{mix deps.get}{list:mixdepsget}{listings/mix-deps-get}

\texttt{\$ mix deps}

Then finally install the libraries
\includecode{mix deps}{lst:mixdeps2}{listings/mix-deps2}

If you get the information that the packages are outdated (not compiled) then 
follow the hint and issue \texttt{mix deps.compile}, even though the next time
your project will be compiled the dependencies also get compiled. But we will 
do that right away.

\texttt{\$ mix deps.compile}

\includecode{mix deps.compile}{lst:mixdepscompile}{listings/mix-deps-compile}

If you look at your project tree you will see a new directory \texttt{deps}. 
There you will find all the dependencies you have just compiled. 

Now we are good to go.

\subsection{Fetching Data from NOAA}
Except for the \texttt{:help} function we only have dummy implementations. We
now want to implement \texttt{:datasets}, \texttt{:locations} and 
\texttt{:data}. We will host these functions in the \texttt{Noaa.Webservice} 
module.

We first write the test with a stub implementation of \texttt{Noaa.Webservice}
in place.

\includecode{lib/noaa/webservice.ex}{lst:webservice}{listings/webservice.ex}

\includecode{test/test\_webservice.exs}{lst:webservicetest}
            {listings/webservice.ex}

To get \texttt{HTTPoison} to work it has to be started as a separate 
application. Actually we don't have to do that manually we rather add 
\texttt{HTTPoison} to \texttt{mix.exs} in the \texttt{application} section.

\includecode{mix.exs with HTTPoison}{lst:mixexsHTTPoison}{listings/mix1.exs}

When we run the test it will fail. We then implement \texttt{Noaa.Webservice} 
and run the test again.

\includecode{list/noaa/webservice.ex}{lst:webservice1}{listings/webservice1.ex}

And when we run the test now it will be executed without errors. Actually we 
are only checking for the \texttt{:ok} response from the web service and ignore
the body. If we get the data right we will see when we do the printing of the
results. What we test here that we successfully can obtain data over the web 
service. Actually this isn't a good idea to access the web service in tests.
For one accesses are limited per day and two if we are running a lot of tests,
what we actually should, it might put heavy load to the server. If we are done
we can skip these tests. But for now (NOAA forgive me) we will use them.

Currently \texttt{Noaa:Webservice.fetch} is returning the raw data from 
\texttt{NOAA}. But what we want is the data in a way we can handle them more
easily. This is the next step in our process chain. We are converting the data
to an internal representation.

\section{Converting the Response Data}
The response from \texttt{NOAA} is in \texttt{JSON} format. To convert it to a
data structure we use the previously installed \texttt{jsx} library. In the
\texttt{Noaa.Webservice} we convert the data with \texttt{jsx}.

\includecode{lib/noaa/webservice.ex}{lst:webservice2}{listings/webservice2.ex}

Our test should still pass, as we are not checking for the body, but only for
the \texttt{:ok} response.

If we look the converted data it looks like in \ref{lst:jsonformat} on page
\pageref{lst:jsonformat}.

\includecode{JSON format of webservice response}{lst:jsonformat}
            {listings/json-format}

We can use our application in \texttt{iex} by starting \texttt{iex} with the
\texttt{\$ mix -S mix} switch.

\begin{verbatim}
\$ iex -S mix
Erlang/OTP 17 [erts-6.3] [source] [64-bit] [smp:4:4] [async-threads:10] 
[kernel-poll:false]
Compiled lib/noaa.ex
Compiled lib/noaa/webservice.ex
lib/noaa/cli.ex:105: warning: variable city is unused
Compiled lib/noaa/cli.ex
Generated noaa.app
Interactive Elixir (1.0.2) - press Ctrl+C to exit (type h() ENTER for help)
iex(1)>
iex(1)> ds = Noaa.Webservice.fetch("http://www.ncdc.noaa.gov/cdo-web/api/v2/data
sets?limit=1")
{:ok,
 [{"results",
   [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
     {"name", "Annual Summaries"}, {"datacoverage", 1},
     {"mindate", "1831-02-01"}, {"maxdate", "2014-07-01"}]]},
  {"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]}]}
\end{verbatim}

We acutally want to work with the \texttt{"results"} and the 
\texttt{"metadata"}. We can destructure the \texttt{tuple} with a pattern match.

\begin{verbatim}
iex(2)> { _ , body } = ds
{:ok,
 [{"results",
   [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
     {"name", "Annual Summaries"}, {"datacoverage", 1},
     {"mindate", "1831-02-01"}, {"maxdate", "2014-07-01"}]]},
  {"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]}]}
iex(3)> body
[{"results",
  [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
    {"name", "Annual Summaries"}, {"datacoverage", 1},
    {"mindate", "1831-02-01"}, {"maxdate", "2014-07-01"}]]},
 {"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]}]
\end{verbatim}

To access the \texttt{"results"} and the \texttt{"metadata"} with pattern
matching or with \texttt{List.keyfind}. First we destructure the body with
pattern matching.

\begin{verbatim}
iex(52)> [ results, metadata ] = body
[{"results",
  [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
    {"name", "Annual Summaries"}, {"datacoverage", 1},
    {"mindate", "1831-02-01"}, {"maxdate", "2014-07-01"}]]},
 {"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]}]
iex(53)> results
{"results",
 [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
   {"name", "Annual Summaries"}, {"datacoverage", 1}, {"mindate", "1831-02-01"},
   {"maxdate", "2014-07-01"}]]}
iex(54)> metadata
{"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]}
\end{verbatim}

We do the same now with \texttt{List.keyfind}.

\begin{verbatim}
iex(4)> results = List.keyfind(body, "results", 0)
{"results",
 [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
   {"name", "Annual Summaries"}, {"datacoverage", 1}, {"mindate", "1831-02-01"},
   {"maxdate", "2014-07-01"}]]} 
iex(5)> meta = List.keyfind(body, "metadata", 0)
{"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]} 
\end{verbatim}

The pattern matching is a conciser. We can destructure the body into the
\texttt{"results"} and \texttt{"metadata"} in one swoop as we need two 
commands with \texttt{List.keyfind}.

This is not yet the data we need. What we want to do is iterate or recurse
through the data of \texttt{"results"} and \texttt{"metadata"}'s 
\texttt{resultset}. That is we just need the data of these two and then put 
it into a collection. To retrieve the data we will now do all in one swoop 
with pattern matching.
Note that the \texttt{resultset} in nested in the \texttt{metadata}, so we
have also a nested pattern to destructure the data.

\begin{verbatim}
iex(6)> [ {r, rd}, { m, [ { rs, rsd } ] } ] = body
[{"results",
  [[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
    {"name", "Annual Summaries"}, {"datacoverage", 1},
    {"mindate", "1831-02-01"}, {"maxdate", "2014-07-01"}]]},
 {"metadata", [{"resultset", [{"limit", 1}, {"count", 11}, {"offset", 1}]}]}]
iex(7)> r
"results"
iex(8)> rd
[[{"uid", "gov.noaa.ncdc:C00040"}, {"id", "ANNUAL"},
  {"name", "Annual Summaries"}, {"datacoverage", 1}, {"mindate", "1831-02-01"},
  {"maxdate", "2014-07-01"}]]
iex(9)> m
"metadata"
iex(92)> rs
"resultset"
iex(93)> rsd
[{"limit", 1}, {"count", 11}, {"offset", 1}]
\end{verbatim}

I think that is quite cool how \texttt{Elixir} can destructure a collection.
Now both the \texttt{"results"} data and the \texttt{"metadata"} data we 
want to put into a \texttt{HashDict} so we can access the values with
\texttt{results["id"]} or just use comprehensions. To put the data into a 
\texttt{HashDict} we use \texttt{Enum.map} and \texttt{Enum.into}.

\begin{verbatim}
iex(97)> result = rd |> Enum.map(&Enum.into(&1, HashDict.new))
[#HashDict<[{"name", "Annual Summaries"}, {"maxdate", "2014-07-01"},
  {"id", "ANNUAL"}, {"mindate", "1831-02-01"}, {"uid", "gov.noaa.ncdc:C00040"},
  {"datacoverage", 1}]>]
iex(98)> resultset = rsd |> Enum.into(HashDict.new)
#HashDict<[{"limit", 1}, {"count", 11}, {"offset", 1}]> 
\end{verbatim}

Now we can access the data with the \texttt{Dict} interface.

\begin{verbatim}
iex(112)> resultset
#HashDict<[{"limit", 1}, {"count", 11}, {"offset", 1}]>
iex(113)> HashDict.keys h
["name", "maxdate", "id", "mindate", "uid", "datacoverage"]
iex(114)> HashDict.keys resultset
["limit", "count", "offset"]
iex(115)> resultset["count"]
11
iex(116)> [ h | t ] = result
[#HashDict<[{"name", "Annual Summaries"}, {"maxdate", "2014-07-01"},
  {"id", "ANNUAL"}, {"mindate", "1831-02-01"}, {"uid", "gov.noaa.ncdc:C00040"},
  {"datacoverage", 1}]>]
iex(117)> HashDict.keys h
["name", "maxdate", "id", "mindate", "uid", "datacoverage"]
iex(118)> h["maxdate"]
"2014-07-01"
iex(119)> HashDict.get(h, "mindate")
"1831-02-01"
\end{verbatim}

We now now how to retrieve the data. Back in the \texttt{Noaa.CLI} module 
we will decode the repsonse accordingly in the \texttt{process} functions.

We will first write a test but again we cannot test for error response 
when we issue a \texttt{System.halt} what we will do when the response
returns an error. Therefore we test only the success response \texttt{:ok}.

\includecode{test/decode\_test.exs}{lst:decodetest}
            {listings/decode-test.exs}

The implementation of the \texttt{decode\_response} follows.

\includecode{lib/noaa/cli.ex}{lst:cli6}{listings/cli6.ex}

And when we run the test it will pass.

Next we want to transform the data \texttt{results} and \texttt{metadata} 
into a \texttt{HashDict}. As we do that we have seen in ...

Again we start with a test.

\includecode{test/transform\_test.exs}{lst:transformtest}
            {listings/transform-test.exs}

And here the respective implementation of 
\texttt{convert\_to\_list\_of\_hashdicts}.

\includecode{lib/cli7.ex}{lst:cli7}{listings/cli7.ex}

The next step in our implementation is to print the data to the console.

\section{Print the Results}
Printing the data is the actual result of our application. We will format
the data as a table. To nicely format it we have to determine the max length
of each value to have each column the same size. We also want to choose
which values to show dependent on the command, that is \texttt{datasets},
\texttt{locations} and \texttt{data}. All of these have metadata that is
printed with each of the data.

\subsection{Design the metadata Table}
The \texttt{metadata} gives information about the data retrieved from
\texttt{NOAA}. The \texttt{metadata} is shown in table 
\ref{tbl:metadatadata}.

\begin{table}[h]\footnotesize
  \caption{Data of \texttt{metadata}}
  \begin{tabular}{p{5cm} p{7cm}}
    \hline
    \textbf{Data} & \textbf{Example} \\
    \hline
    "limit"   & "1" \\
    "count"   & "11" \\
    "offset"  & "1" \\
    \hline
    \label{tbl:metadatadata}
  \end{tabular}
\end{table}

\subsection{Design the datasets Table}
The \texttt{datasets} describes the type of data that can be obtained with
the \texttt{data} webservice. The \texttt{datasets} contains the data in
table \ref{tbl:datasetsdata}.

\begin{table}[h]\footnotesize
  \caption{Data of \texttt{datasets}}
  \begin{tabular}{p{5cm} p{7cm}}
    \hline
    \textbf{Data} & \textbf{Example} \\
    \hline
    "name"         & "Annual Summaries" \\
    "id"           & "ANNUAL" \\
    "mindate"      & "1831-02-01" \\
    "maxdate"      & "2014-07-01" \\
    "datacoverage" & 1 \\
    \hline
    \label{tbl:datasetsdata}
  \end{tabular}
\end{table}

\subsection{Design the locations Table}
The \texttt{locations} is the location for which the weather data can be 
obtained from. Table \ref{tbl:locationsdata} shows the layout.

\begin{table}[h]\footnotesize
  \caption{Data of \texttt{locations}}
  \begin{tabular}{p{5cm} p{7cm}}
    \hline
    \textbf{Data} & \textbf{Example} \\
    \hline
    "name"         & "Ajman, AE" \\
    "id"           & "CITY:AE000002" \\
    "mindate"      & "1944-03-01" \\
    "maxdate"      & "2014-12-30" \\
    "datacoverage" & 0.6855 \\
    \hline
    \label{tbl:locationsdata}
  \end{tabular}
\end{table}

\subsection{Design the data Table}
This is actually the weather data we want to display for a location. Table
\ref{tbl:datadata} shows the design of the \texttt{data} table.

\begin{table}[h]\footnotesize
  \caption{Data of \texttt{data}}
  \begin{tabular}{p{5cm} p{7cm}}
    \hline
    \textbf{Data} & \textbf{Example} \\
    \hline
    "datatype"   & "PRCP" \\
    "value"      & 14 \\
    "station"    & "GHCND:GM00004199" \\
    "attributes" & ",,E," \\
    "date"       & "2014-10-01" \\
    \hline
    \label{tbl:datadata}
  \end{tabular}
\end{table}

\subsection{Implementation of TableFormatter}
Based on the design of the table formats of the different data types we are
ready for the implementation. We provide the fields we want to display to
the \texttt{TableFormatter}. The \texttt{TableFormatter} looks for the 
largest fields in each column and creates the column layout accordingly.

As usual test first, we write the test for the \texttt{TableFormatter}.

\includecode{test/table\_formatter\_test.exs}{lst:tableformattertest}
            {listings/table-formatter-test.exs}

Now to the implememtation of the \texttt{TableFormatter} module.

\includecode{lib/noaa/table\_formatter.ex}{lst:tableformatter}
            {listings/table-formatter.ex}

Now we have all pieces available and can finalize the application. We update
the \texttt{process} functions in \texttt{lib/noaa/cli.ex} after we have
written the respective test as shown in \ref{lst:cliprocesstest2}.

\includecode{test/cli\_process\_test}{lst:cliprocesstest2}
            {listings/cli_process_test2.exs}

Then we do the final implementation in \texttt{lib/cli.ex}.

\includecode{lib/noaa/cli.ex}{lst:cli7}{listings/cli7.ex}

When we run the test they should all pass. Except for one test for that we
didn't do the implemenation. \texttt{process({:locations, city})} we haven't
implemented yet. We also should extend our interface by the \texttt{limit}
switch. Currently when invoking \texttt{:datasets} or \texttt{:locations} we
always start at the first record. This is actually not usefull. We cover 
those two pending topics (maybe) later.

We are ready to go with our nicely implemented application. We can test it 
from the commandline or within \texttt{iex}. Lets test it in \texttt{iex}.

\begin{verbatim}
\$ iex -S mix
iex(1)> Noaa.CLI.process({:datasets, 12})
Datasets
name                      | id         | mindate    | maxdate    | datacoverage
--------------------------+------------+------------+------------+-------------
Annual Summaries          | ANNUAL     | 1831-02-01 | 2014-07-01 | 1         
Daily Summaries           | GHCND      | 1763-01-01 | 2014-12-31 | 1        
Monthly Summaries         | GHCNDMS    | 1763-01-01 | 2014-12-01 | 1       
Weather Radar (Level II)  | NEXRAD2    | 1991-06-05 | 2015-01-04 | 0.95     
Weather Radar (Level III) | NEXRAD3    | 1994-05-20 | 2015-01-01 | 0.95     
Normals Annual/Seasonal   | NORMAL_ANN | 2010-01-01 | 2010-01-01 | 1       
Normals Daily             | NORMAL_DLY | 2010-01-01 | 2010-12-31 | 1       
Normals Hourly            | NORMAL_HLY | 2010-01-01 | 2010-12-31 | 1      
Normals Monthly           | NORMAL_MLY | 2010-01-01 | 2010-12-01 | 1     
Precipitation 15 Minute   | PRECIP_15  | 1970-05-12 | 2013-07-01 | 0.25 
Precipitation Hourly      | PRECIP_HLY | 1900-01-01 | 2013-10-01 | 1    
                                                                       
Metadata
limit | count | offset
------+-------+-------
12    | 11    | 1     
iex(2)> Noaa.CLI.process({:locations, 10})
                                          
Locations
name            | id            | mindate    | maxdate    | datacoverage
----------------+---------------+------------+------------+-------------
Ajman, AE       | CITY:AE000002 | 1944-03-01 | 2014-12-30 | 0.6859      
Dubai, AE       | CITY:AE000003 | 1944-03-01 | 2014-12-30 | 0.6859      
Sharjah, AE     | CITY:AE000006 | 1944-03-01 | 2014-12-30 | 0.6859      
Algiers, AG     | CITY:AG000001 | 1877-04-01 | 2014-12-30 | 1          
Annaba, AG      | CITY:AG000002 | 1909-11-01 | 1937-12-31 | 0.9527    
Bejaia, AG      | CITY:AG000005 | 1909-11-01 | 1938-12-29 | 0.9596   
Constantine, AG | CITY:AG000006 | 1880-05-01 | 1938-12-30 | 0.8736  
Laghouat, AG    | CITY:AG000008 | 1888-01-01 | 1938-12-30 | 0.9036 
Tamanrasset, AG | CITY:AG000016 | 1940-01-01 | 2014-02-18 | 0.9989
Baku, AJ        | CITY:AJ000001 | 1881-07-01 | 1992-01-31 | 0.991 
                                                                 
Metadata
limit | count | offset
------+-------+-------
10    | 38497 | 1    

iex(3)> Noaa.CLI.process({:data, [dataset: "GHCND", \
        location: "CITY:AE000002", from: "2014-10-01", to: "2014-10-01"]})

Weather Data
datatype | value | station           | attributes | date
---------+-------+-------------------+------------+--------------------
PRCP     | 0     | GHCND:AE000041196 | ,,S,       | 2014-10-01T00:00:00
TMAX     | 381   | GHCND:AE000041196 | ,,S,       | 2014-10-01T00:00:00
TMIN     | 285   | GHCND:AE000041196 | ,,S,       | 2014-10-01T00:00:00

Metadata
limit | count | offset
------+-------+-------
25    | 3     | 1     
\end{verbatim}

\section{Make the Command-Line Executable}
What we want to do is call our application from the command line without the
\texttt{Elixir} command. To enable this for our application we have to add
\texttt{[ main\_module: Noaa.CLI ]} to \texttt{mix.exs} like shown in 
listing \ref{lst:mix2exs}.

\includecode{mix.exs}{lst:mix2exs}{listings/mix2.exs}

\texttt{escript} is \texttt{Erlang} utility that can run \texttt{Zip} 
archives that contain pre-compiled applications. \texttt{escript} requires
a \texttt{main} function in the \texttt{module} depicted in the 
\texttt{escript} directive in \texttt{mix.exs}. The \texttt{main} function
in \texttt{Noaa.CLI} is actuall the \texttt{run} function. So the only thing
we have to do is to rename \texttt{run} to \texttt{main}.

\includecode{lib/noaa/cli.ex}{lst:cli8}{listings/cli8.ex}

To make our application executable we package it with 
\texttt{\$ mix escript.build}.
    
\begin{verbatim}
$ mix escript.build
Compiled lib/noaa.ex
Compiled lib/noaa/webservice.ex
Compiled lib/noaa/table_formatter.ex
lib/noaa/cli.ex:105: warning: variable city is unused
Compiled lib/noaa/cli.ex
Generated noaa.app
Consolidated List.Chars
Consolidated Access
Consolidated Collectable
Consolidated String.Chars
Consolidated Inspect
Consolidated Enumerable
Consolidated Range.Iterator
Consolidated protocols written to _build/dev/consolidated
Generated escript noaa with MIX_ENV=dev
\end{verbatim}

Now let's test it from the command line with \texttt{\$ ./noaa}

\begin{verbatim}
$ ./noaa --datasets 12

Datasets
name                      | id         | mindate    | maxdate    | datacoverage
--------------------------+------------+------------+------------+-------------
Annual Summaries          | ANNUAL     | 1831-02-01 | 2014-07-01 | 1        
Daily Summaries           | GHCND      | 1763-01-01 | 2014-12-31 | 1        
Monthly Summaries         | GHCNDMS    | 1763-01-01 | 2014-12-01 | 1        
Weather Radar (Level II)  | NEXRAD2    | 1991-06-05 | 2015-01-04 | 0.95     
Weather Radar (Level III) | NEXRAD3    | 1994-05-20 | 2015-01-01 | 0.95     
Normals Annual/Seasonal   | NORMAL_ANN | 2010-01-01 | 2010-01-01 | 1        
Normals Daily             | NORMAL_DLY | 2010-01-01 | 2010-12-31 | 1        
Normals Hourly            | NORMAL_HLY | 2010-01-01 | 2010-12-31 | 1        
Normals Monthly           | NORMAL_MLY | 2010-01-01 | 2010-12-01 | 1        
Precipitation 15 Minute   | PRECIP_15  | 1970-05-12 | 2013-07-01 | 0.25     
                                                                            
Metadata
limit | count | offset
------+-------+-------
10    | 11    | 1     
\end{verbatim}

\section{Commenting the functions}
This is something I should have done while coding. After being done it is 
quite cumbersome. But nevertheless \texttt{Elixir} comes with a fantastic
documentation feature that allows you not only to insert code like you 
would test your application in \texttt{iex} but it also tests whether this
code actually runs. Let's document the \texttt{lib/noaa/table\_formatter.ex}
module as this is the only one where we can create \texttt{iex} commands without
reaching for the \texttt{NOAA} webservice over the internet.

\includecode{lib/noaa/table\_formatter.ex}{lst:tableformatter2}
            {listings/table-formatter2.ex}

To test the comments, that is the included \texttt{iex} commands we write a
short test that checks that the commands are valid.

\includecode{test/doc\_test.exs}{lst:doctest}{listings/doc-test.exs}

We run the test with \texttt{mix} as we test all our code.

\begin{verbatim}
pierre@saltspring:~/Learn/Elixir/noaa$ mix test test/doc_test.exs
Compiled lib/noaa/table_formatter.ex
lib/noaa/cli.ex:149: warning: variable city is unused
Compiled lib/noaa/cli.ex
Generated noaa.app
...

Finished in 0.1 seconds (0.1s on load, 0.00s on tests)
3 tests, 0 failures

Randomized with seed 362781 
\end{verbatim}

\section{Project Documentation}
\texttt{Elixir} also comes equipped with a documentation generator called
\texttt{ExDoc}. To utilize this we have to add it to our dependencies in our
\texttt{mix.exs} file. \texttt{ExDoc} also provides a nice feature to link
to the \texttt{Github} hosted source code. To use that we add the
\texttt{Github-URL} into the \texttt{application} section in \texttt{mix.exs}.

\includecode{mix.exs}{lst:mix3}{listings/mix3.exs}

To install \texttt{ExDoc} issue the command \texttt{\$ mix deps.get} from
the command line. To create the documentation call \texttt{\$ mix docs}. If 
you get an error saying 

\begin{verbatim}
** (RuntimeError) Could not find a markdown processor to be used by ex_doc.
You can either:

* Add {:earmark, ">= 0.0.0"} to your mix.exs deps
  to use an Elixir-based markdown processor

* Add {:markdown, github: "devinus/markdown"} to your mix.exs deps
  to use a C-based markdown processor

* Ensure pandoc (http://johnmacfarlane.net/pandoc) is available in your syst$
m
  to use it as an external tool
\end{verbatim}

Then follow the instructions. For instance add \texttt{earmark} as 
dependency.

\includecode{mix.exs}{lst:mix4}{listings/mix4.exs}

Then try again \texttt{\$ mix deps.get} and it should create your 
documentation.

\begin{verbatim}
pierre@saltspring:~/Learn/Elixir/noaa$ mix docs
==> earmark
Compiled lib/earmark/context.ex
Compiled lib/earmark.ex
Compiled lib/earmark/cli.ex
Compiled lib/earmark/helpers.ex
Compiled lib/earmark/inline.ex
Compiled lib/earmark/parser.ex
Compiled lib/earmark/html_renderer.ex
Compiled lib/earmark/line.ex
Compiled lib/earmark/block.ex
Generated earmark.app
==> noaa
Compiled lib/noaa.ex
Compiled lib/noaa/webservice.ex
Compiled lib/noaa/table_formatter.ex
lib/noaa/cli.ex:149: warning: variable city is unused
Compiled lib/noaa/cli.ex
Generated noaa.app
Docs successfully generated.
View them at "doc/index.html".
\end{verbatim}

Now open \texttt{doc/index.html} and you will see a nicely formatted 
application documentation.

\section{Closing}
So that's it as a brief overview. That was a lot stuff. But we scratched
only the surface of \texttt{Elixir}. What we didn't cover is 
\texttt{logging}and multi processing. This is all nicely covered by 
Dave Thomas' book \texttt{Programming Elixr} which can be found at 
\url{https://pragprog.com/book/elixir/programming-elixir}. This short 
description is based on the book from Dave Thomas. As Elixir is a quite new 
language there are only 2 books
available at the moment. You can find them all at \url{http://elixir-lang.org/}. 
\end{document}
